{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in original data sets\n",
    "df_training = pd.read_csv('../data/archive/train.csv')\n",
    "df_testing = pd.read_csv('../data/archive/test.csv')\n",
    "\n",
    "# loading in pca data sets\n",
    "df_training_pca = pd.read_csv('../data/archive/train_pca.csv')\n",
    "df_testing_pca = pd.read_csv('../data/archive/test_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the normal training and test data\n",
    "\n",
    "x_train = df_training.iloc[:, :-2]\n",
    "y_train = df_training.iloc[:,-1]\n",
    "\n",
    "x_test = df_testing.iloc[:, :-2]\n",
    "y_test = df_testing.iloc[:,-1]\n",
    "\n",
    "# get the pca training and test data\n",
    "\n",
    "x_train_pca = df_training_pca.iloc[:, :-1]\n",
    "y_train_pca = df_training_pca.iloc[:,-1]\n",
    "\n",
    "x_test_pca = df_testing_pca.iloc[:, :-1]\n",
    "y_test_pca = df_testing_pca.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best parameters set found on training set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.885 (+/-0.046) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.898 (+/-0.064) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.885 (+/-0.047) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.906 (+/-0.054) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.897 (+/-0.070) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.908 (+/-0.049) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.902 (+/-0.060) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.900 (+/-0.050) for {'C': 1, 'kernel': 'linear'}\n",
      "0.897 (+/-0.052) for {'C': 10, 'kernel': 'linear'}\n",
      "0.897 (+/-0.056) for {'C': 100, 'kernel': 'linear'}\n",
      "0.896 (+/-0.055) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report using best parameters:\n",
      "\n",
      "The model is trained on the training set.\n",
      "The scores are computed on the test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       537\n",
      "           2       0.90      0.93      0.91       532\n",
      "           3       0.92      0.88      0.90       491\n",
      "           4       0.91      0.92      0.92       496\n",
      "           5       0.85      0.87      0.86       471\n",
      "           6       0.91      0.88      0.90       420\n",
      "\n",
      "    accuracy                           0.92      2947\n",
      "   macro avg       0.92      0.91      0.92      2947\n",
      "weighted avg       0.92      0.92      0.92      2947\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for precision_micr0\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'precision_micr0' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m                 \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'precision_micr0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0d8c973a94da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     )\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on training set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[0;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    474\u001b[0m                                                           str):\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    403\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0m\u001b[0;32m    363\u001b[0m                              \u001b[1;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m                              'to get valid options.' % scoring)\n",
      "\u001b[1;31mValueError\u001b[0m: 'precision_micr0' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "source": [
    "# hyper parameters to test: kernel, C, gamma\n",
    "\n",
    "# parameters to test\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "best_param_dict = {}\n",
    "\n",
    "# scoring on accuracy, precicsion_micro and f1_micro\n",
    "scores = ['accuracy', 'precision_micro', 'f1_micro']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    clf = GridSearchCV(\n",
    "        svm.SVC(), param_grid, scoring= score\n",
    "    )\n",
    "    clf.fit(x_train_pca, y_train_pca)\n",
    "\n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on training set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report using best parameters:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the training set.\")\n",
    "    print(\"The scores are computed on the test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_pca, clf.predict(x_test_pca)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.77      0.82       537\n",
      "           2       0.52      0.43      0.47       532\n",
      "           3       0.38      0.52      0.44       491\n",
      "           4       0.59      0.89      0.71       496\n",
      "           5       0.89      0.67      0.76       471\n",
      "           6       0.58      0.37      0.45       420\n",
      "\n",
      "    accuracy                           0.61      2947\n",
      "   macro avg       0.64      0.61      0.61      2947\n",
      "weighted avg       0.64      0.61      0.61      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(C= 100, gamma= 0.0001, kernel= 'rbf')\n",
    "clf.fit(x_train_pca, y_train_pca)\n",
    "\n",
    "y_true, y_pred = y_test_pca, clf.predict(x_test_pca)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
